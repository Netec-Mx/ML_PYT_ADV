### 游 Pr치ctica 7: Construcci칩n y Aplicaciones de Redes Neuronales

### **Objetivos de la Pr치ctica** 游꿢

  * Comprender el **dise침o y la configuraci칩n** de arquitecturas de redes neuronales.
  * Conocer metodolog칤as de **entrenamiento y validaci칩n** para un rendimiento 칩ptimo.
  * Entender los **fundamentos y la aplicaci칩n** de las **Redes Neuronales Convolucionales (CNN)** en la visi칩n por computadora.
  * Explorar c칩mo las operaciones de **convoluci칩n** extraen caracter칤sticas de las im치genes.

**Duraci칩n aproximada:**
- 60 minutos.

**Tabla de ayuda:**

Para la ejecuci칩n del c칩digo ingresar a https://colab.research.google.com/ 

### **1. Configuraci칩n y Entrenamiento de Redes Neuronales**

En esta secci칩n, nos centraremos en los aspectos pr치cticos de la construcci칩n de modelos, utilizando el conjunto de datos de la moda de **Fashion-MNIST**. Este *dataset* es ideal para la clasificaci칩n de im치genes a peque침a escala y consta de 10 categor칤as de prendas de vestir. En este ejercicio, construir치s una red neuronal densa, donde cada neurona est치 conectada a todas las neuronas de la capa anterior.

Para usar las im치genes de Fashion-MNIST en una red densa, primero se **aplanan** la cuadr칤cula de p칤xeles (28x28) en un solo vector de 784 p칤xeles. Esto permite que el modelo procese la imagen como una secuencia de n칰meros. Las capas subsiguientes (`Dense`) aprenden a reconocer patrones en estos datos aplanados para clasificar la prenda.

#### **Ejercicio:**

Dise침a y entrena una red neuronal con m칰ltiples capas para clasificar las 10 categor칤as de im치genes en el conjunto de datos de Fashion-MNIST.

```python
import tensorflow as tf
from tensorflow import keras
import numpy as np

# Cargar el conjunto de datos
(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()

# Preprocesamiento de datos
X_train = X_train / 255.0
X_test = X_test / 255.0

# 1. Dise침ar el modelo
modelo_fashion = keras.Sequential([
    keras.Input(shape=(28, 28)), # Capa de entrada recomendada para evitar la advertencia
    keras.layers.Flatten(),
    keras.layers.Dense(128, activation='relu'),
    keras.layers.Dense(10, activation='softmax') # Capa de salida para 10 clases
])

# 2. Compilar el modelo
modelo_fashion.compile(optimizer='adam',
                       loss='sparse_categorical_crossentropy',
                       metrics=['accuracy'])

# 3. Entrenar el modelo
print("Entrenando el modelo...")
modelo_fashion.fit(X_train, y_train, epochs=10, verbose=1)

# 4. Evaluar la precisi칩n
test_loss, test_acc = modelo_fashion.evaluate(X_test, y_test, verbose=2)
print(f"\nPrecisi칩n en el conjunto de prueba: {test_acc*100:.2f}%")
```

**Reto:** Experimenta con la arquitectura de la red. Agrega una capa oculta adicional con `Dense(64, activation='relu')` y entrena el modelo de nuevo. 쯄ejora o empeora el rendimiento?

```python
# Pista de c칩digo para el reto:
# Para agregar la nueva capa, necesitas insertar una l칤nea de c칩digo en la lista de capas dentro de keras.Sequential.
# Piensa d칩nde ser칤a m치s l칩gico colocar la nueva capa de 64 neuronas para que la informaci칩n fluya correctamente a trav칠s del modelo.
# Por lo general, las capas se colocan de mayor a menor tama침o para permitir un aprendizaje progresivo de las caracter칤sticas.

# Pista: Completa la lista de capas.
modelo_fashion_reto = keras.Sequential([
    keras.Input(shape=(28, 28)),
    keras.layers.Flatten(),
    keras.layers.Dense(128, activation='relu'),
    # Inserta aqu칤 la nueva capa Dense con 64 neuronas y funci칩n de activaci칩n 'relu'
    # ...
    keras.layers.Dense(10, activation='softmax')
])

# No olvides compilar y entrenar el nuevo modelo despu칠s de definirlo.
```

-----

### **2. Fundamentos de Redes Convolucionales (CNN)**

Las CNN son un tipo de red neuronal especializado para procesar datos con una topolog칤a conocida, como las im치genes. A diferencia de las redes densas, que aplanan la imagen, las CNN trabajan directamente con la cuadr칤cula de p칤xeles, utilizando operaciones de **convoluci칩n** para escanear la imagen y detectar patrones como bordes, texturas y formas. Una **capa de pooling** se usa para reducir la dimensionalidad y hacer el modelo m치s eficiente. Juntas, estas operaciones crean una representaci칩n jer치rquica de la imagen que es muy efectiva.

En este ejercicio, construir치s una CNN simple para ver c칩mo este enfoque mejora la precisi칩n en la clasificaci칩n de im치genes en comparaci칩n con la red densa del ejercicio anterior.

#### **Ejercicio:**

Construye una CNN simple y apl칤cala al mismo conjunto de datos de Fashion-MNIST.

```python
import tensorflow as tf
from tensorflow import keras
import numpy as np

# Cargar y preprocesar los datos
(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()

# Redimensionar las im치genes para la capa de convoluci칩n
# (n칰mero_muestras, altura, anchura, canales)
# El canal es 1 porque las im치genes son en escala de grises
X_train_cnn = X_train[..., np.newaxis] / 255.0
X_test_cnn = X_test[..., np.newaxis] / 255.0

# 1. Dise침ar la CNN
modelo_cnn = keras.Sequential([
    keras.Input(shape=(28, 28, 1)), # Capa de entrada recomendada para evitar la advertencia
    keras.layers.Conv2D(32, (3, 3), activation='relu'),
    keras.layers.MaxPooling2D((2, 2)), # Capa de pooling para reducir la dimensionalidad
    keras.layers.Flatten(),
    keras.layers.Dense(64, activation='relu'),
    keras.layers.Dense(10, activation='softmax')
])

# 2. Compilar y entrenar el modelo
modelo_cnn.compile(optimizer='adam',
                   loss='sparse_categorical_crossentropy',
                   metrics=['accuracy'])

print("Entrenando la CNN...")
modelo_cnn.fit(X_train_cnn, y_train, epochs=5, verbose=1)

# 3. Evaluar la precisi칩n
test_loss_cnn, test_acc_cnn = modelo_cnn.evaluate(X_test_cnn, y_test, verbose=2)
print(f"\nPrecisi칩n de la CNN en el conjunto de prueba: {test_acc_cnn*100:.2f}%")
```

**Reto:** Modifica el modelo para que incluya una segunda capa de **convoluci칩n** y otra de *pooling*. 쮺칩mo afecta esto al rendimiento y al tiempo de entrenamiento?

```python
# Pista de c칩digo para el reto:
# Para este reto, tu objetivo es hacer que el modelo sea m치s profundo para ver si puede aprender caracter칤sticas m치s complejas.
# Esto se logra apilando capas de convoluci칩n y pooling antes de la capa Flatten.
# Recuerda que cada capa de convoluci칩n crea m치s feature maps o mapas de caracter칤sticas
# (a menudo se duplica el n칰mero de filtros) para que el modelo pueda aprender de forma m치s granular.

# Pista: Completa la secuencia de capas.
modelo_cnn_reto = keras.Sequential([
    keras.Input(shape=(28, 28, 1)),
    keras.layers.Conv2D(32, (3, 3), activation='relu'),
    keras.layers.MaxPooling2D((2, 2)),
    # Agrega aqu칤 tu segunda capa Conv2D (puedes usar 64 filtros)
    # Agrega aqu칤 tu segunda capa MaxPooling2D
    # ...
    keras.layers.Flatten(),
    keras.layers.Dense(64, activation='relu'),
    keras.layers.Dense(10, activation='softmax')
])

# No olvides compilar y entrenar el nuevo modelo y comparar sus resultados con el modelo anterior.
```
